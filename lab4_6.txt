List04_06:::

[pyspark, <, sample.py]
[pyspark, --packages, org.apache.spark.sql, <, sample.py]


    external_links:
      - mongodb

sudo zip -r lsdp_4_5.zip project_1

1) Why Java: spark is written in Java due to complexity optimization
2) Java 8 needed?: Yes, Spark runs on Java 8+
3) External cluster connection available?: 
4) Code deployment to Spark cluster?: 
5) Spark jobs observation:
6) Logistic regression --> non-linear regression
7) Multi-class: many classes and only one could be assigned; Multi-label: many classes and many could be assigned
8) RDD - Resilent Distributed Dataset: immutable dataset which can be multiprocessed; transformations & actions (parallelize)
9) Dataframe - mutable table-looking data structure
10) DataSet - datasets created from sql query
11) Master: SparkContext; Worker: Pipelines


Same container for Spark and Flask. --> webspark


